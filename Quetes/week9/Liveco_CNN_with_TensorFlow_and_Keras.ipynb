{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"429b605cc2d54d5bb2998dff15c1213a","deepnote_cell_type":"markdown","id":"9McRkqNvscOz"},"source":["# Image classification with CNN\n","In this quest, you will work with the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).\n","It contains 60000 32x32 colour images in 10 classes, with 6000 images per class. It can be accessed using the load_data() function.\n","Train a CNN on this dataset for image classification.\n"]},{"cell_type":"markdown","metadata":{"cell_id":"43baad8eb628411ea5c8103961b9e781","deepnote_cell_type":"markdown","id":"eLMV7W2SpmS_"},"source":["# Preparation"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"17de4f7fc0eb4aa084b4ec79f490e1de","deepnote_cell_type":"code","execution_context_id":"436619d3-670d-4230-acb4-a964b8bce7ea","execution_millis":10444,"execution_start":1747321743414,"id":"Nh3aDkAmUPMe","source_hash":"39357bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow-datasets in /root/venv/lib/python3.9/site-packages (4.9.3)\n","Requirement already satisfied: wrapt in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (1.14.1)\n","Requirement already satisfied: termcolor in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (3.1.0)\n","Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (1.5.2)\n","Requirement already satisfied: numpy in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (1.25.2)\n","Requirement already satisfied: absl-py in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (2.2.2)\n","Requirement already satisfied: psutil in /toolkit-cache/0.2.16/python3.9/kernel-libs/lib/python3.9/site-packages (from tensorflow-datasets) (6.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (2.32.3)\n","Requirement already satisfied: tensorflow-metadata in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (1.17.1)\n","Requirement already satisfied: promise in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (2.3)\n","Requirement already satisfied: tqdm in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (4.67.1)\n","Requirement already satisfied: dm-tree in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (0.1.8)\n","Requirement already satisfied: protobuf>=3.20 in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (4.21.12)\n","Requirement already satisfied: array-record in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (0.5.1)\n","Requirement already satisfied: click in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (8.1.8)\n","Requirement already satisfied: toml in /root/venv/lib/python3.9/site-packages (from tensorflow-datasets) (0.10.2)\n","Requirement already satisfied: zipp in /root/venv/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.21.0)\n","Requirement already satisfied: fsspec in /toolkit-cache/0.2.16/python3.9/kernel-libs/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (2024.6.1)\n","Requirement already satisfied: importlib_resources in /root/venv/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.5.2)\n","Requirement already satisfied: typing_extensions in /root/venv/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (2025.4.26)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.20)\n","Requirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n","Requirement already satisfied: six in /root/venv/lib/python3.9/site-packages (from promise->tensorflow-datasets) (1.17.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","2025-05-15 15:09:07.977677: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n","2025-05-15 15:09:08.012371: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-05-15 15:09:08.012530: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-05-15 15:09:08.013802: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-05-15 15:09:08.019932: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n","2025-05-15 15:09:08.020737: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-05-15 15:09:10.601466: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/root/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import sys\n","!{sys.executable} -m pip install tensorflow-datasets\n","\n","import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","import tensorflow_datasets as tfds\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"6964aceea51b49e088af3e2e2032e8e3","colab":{"base_uri":"https://localhost:8080/","height":55},"deepnote_cell_type":"code","execution_context_id":"436619d3-670d-4230-acb4-a964b8bce7ea","execution_millis":1804,"execution_start":1747321753914,"id":"vZT5_O_l0bqT","outputId":"330c7255-fa2a-4295-813b-70df5eaaadc3","source_hash":"b7f1c58e"},"outputs":[],"source":["# Loading CIFAR train and test datasets\n","(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"b78d584f4cf647769d6e5df415d6c274","deepnote_cell_type":"code","execution_context_id":"436619d3-670d-4230-acb4-a964b8bce7ea","execution_millis":0,"execution_start":1747321755775,"id":"rgtzfj5f0cfG","source_hash":"4ab31d42"},"outputs":[],"source":["class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n","               'dog', 'frog', 'horse', 'ship', 'truck']"]},{"cell_type":"markdown","metadata":{"cell_id":"b21076c36b47489fbbc13246ef55c3c1","deepnote_cell_type":"markdown","id":"gs2BVhIgsKCD"},"source":["# Tasks"]},{"cell_type":"markdown","metadata":{"cell_id":"2170d9921fd94a9aa89fbde0b5ff1d1b","deepnote_cell_type":"markdown","id":"mp1MM9_DsuhS"},"source":["Normalize pixel values of both train and test images to the values in the range between 0 and 1"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"e5da3a1b6d6a4e049bcb6a7c0a39c879","deepnote_cell_type":"code","execution_context_id":"436619d3-670d-4230-acb4-a964b8bce7ea","execution_millis":205,"execution_start":1747321755825,"id":"lZBGvhl0sDWI","source_hash":"a17ae038"},"outputs":[],"source":["# Normalize pixel values to the range 0-1\n","train_images = train_images / 255.0\n","test_images = test_images / 255.0"]},{"cell_type":"markdown","metadata":{"cell_id":"046b0365604c4eed9d37cdf9073911af","deepnote_cell_type":"markdown","id":"aCaySZ8Ss_aj"},"source":["Build a sequential model with the following architecture:\n","\n","conv2d - (None, 30, 30, 32)  \n","_________________________________________________________________\n","max_pooling2d - (None, 15, 15, 32)        \n","_________________________________________________________________\n","conv2d - (None, 13, 13, 64)\n","_________________________________________________________________\n","max_pooling2d - (None, 6, 6, 64)        \n","_________________________________________________________________\n","conv2d - (None, 4, 4, 128)\n","_________________________________________________________________\n","flatten - (None, 2048)       \n","_________________________________________________________________\n","dense - (None, 64)    \n","_________________________________________________________________\n","dense - (None, 10)       \n"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"59da05d80a9c4427bb35411cf7e5939e","deepnote_cell_type":"code","execution_context_id":"436619d3-670d-4230-acb4-a964b8bce7ea","execution_millis":285,"execution_start":1747321756084,"id":"RFsiddt20yLp","source_hash":"c3910d51"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 30, 30, 32)        896       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n","                                                                 \n"," flatten (Flatten)           (None, 2048)              0         \n","                                                                 \n"," dense (Dense)               (None, 64)                131136    \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 225034 (879.04 KB)\n","Trainable params: 225034 (879.04 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# Building the sequential model\n","model = models.Sequential([\n","    # First Conv2D and MaxPooling layers\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","\n","    # Second Conv2D and MaxPooling layers\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","\n","    # Third Conv2D layer\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","\n","    # Flatten layer\n","    layers.Flatten(),\n","\n","    # Fully Connected Dense layers\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(10)\n","])\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"cell_id":"789ac4bd215b4d9b87fae149676b4d70","deepnote_cell_type":"markdown","id":"2blKJv2huDPh"},"source":["Compile the model using Adam optimizer, sparse categorical crossentropy as loss function, and choose an appropriate metric for classification. Use 10 epochs to train the model."]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"09e85563481f4849b8fdcd50c0f5f0ac","deepnote_cell_type":"code","execution_context_id":"436619d3-670d-4230-acb4-a964b8bce7ea","execution_millis":410391,"execution_start":1747321756434,"id":"flXnIRIG09nO","source_hash":"256a1f1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","2025-05-15 15:09:18.759421: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n","1563/1563 [==============================] - 57s 36ms/step - loss: 1.5153 - accuracy: 0.4464 - val_loss: 1.2508 - val_accuracy: 0.5579\n","Epoch 2/10\n","1563/1563 [==============================] - 46s 29ms/step - loss: 1.1108 - accuracy: 0.6079 - val_loss: 1.0088 - val_accuracy: 0.6435\n","Epoch 3/10\n","1563/1563 [==============================] - 48s 31ms/step - loss: 0.9385 - accuracy: 0.6731 - val_loss: 0.8955 - val_accuracy: 0.6895\n","Epoch 4/10\n","1563/1563 [==============================] - 46s 30ms/step - loss: 0.8323 - accuracy: 0.7097 - val_loss: 0.9097 - val_accuracy: 0.6852\n","Epoch 5/10\n","1563/1563 [==============================] - 44s 28ms/step - loss: 0.7581 - accuracy: 0.7359 - val_loss: 0.8901 - val_accuracy: 0.6913\n","Epoch 6/10\n","1563/1563 [==============================] - 33s 21ms/step - loss: 0.6921 - accuracy: 0.7613 - val_loss: 0.8067 - val_accuracy: 0.7245\n","Epoch 7/10\n","1563/1563 [==============================] - 35s 23ms/step - loss: 0.6487 - accuracy: 0.7728 - val_loss: 0.8536 - val_accuracy: 0.7170\n","Epoch 8/10\n","1563/1563 [==============================] - 32s 21ms/step - loss: 0.5922 - accuracy: 0.7931 - val_loss: 0.8504 - val_accuracy: 0.7174\n","Epoch 9/10\n","1563/1563 [==============================] - 32s 21ms/step - loss: 0.5459 - accuracy: 0.8081 - val_loss: 0.8754 - val_accuracy: 0.7170\n","Epoch 10/10\n","1563/1563 [==============================] - 33s 21ms/step - loss: 0.5100 - accuracy: 0.8221 - val_loss: 0.8835 - val_accuracy: 0.7189\n"]}],"source":["# Compile the model\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"]},{"cell_type":"markdown","metadata":{"cell_id":"fa2420527c6549038a9c03b50d16364e","deepnote_cell_type":"markdown","id":"tyfR1bCiucDE"},"source":["Evaluate the model on test data to get the loss and accuracy metrics"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"96af2cbda276444d8614fdf223d33579","deepnote_cell_type":"code","execution_context_id":"436619d3-670d-4230-acb4-a964b8bce7ea","execution_millis":2008,"execution_start":1747322166874,"id":"CA4Hsi6B035n","source_hash":"698e7eef"},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 - 2s - loss: 0.8835 - accuracy: 0.7189 - 2s/epoch - 6ms/step\n","Test Loss: 0.8835\n","Test Accuracy: 0.7189\n"]}],"source":["# Evaluate the model\n","loss, accuracy = model.evaluate(test_images, test_labels, verbose=2)\n","print(f\"Test Loss: {loss:.4f}\")\n","print(f\"Test Accuracy: {accuracy:.4f}\")"]}],"metadata":{"deepnote_notebook_id":"c6d66379b064483fad0f48b2ec37bac6","language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
