{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"8fa6db197a804e39aa300c8dd3c89baf","deepnote_cell_type":"markdown","id":"0TbaP_BoYOx5"},"source":["# Preparation"]},{"cell_type":"markdown","metadata":{"cell_id":"d007cfc1c4f84b129803214393a1a7a2","deepnote_cell_type":"markdown","id":"Ya9uRJFVb1DQ"},"source":["Install ImageAI."]},{"cell_type":"markdown","metadata":{},"source":["### Remarque :\n","L'exercice demandait initialement d'utiliser la bibliothèque ImageAI avec ResNet pour faire une prédiction d'image.\n","\n","Cependant, ImageAI 2.0.2 dépend de versions spécifiques et anciennes de TensorFlow (<= 2.10) et utilise des modules internes\n","\n","qui ne sont plus disponibles dans les versions récentes de TensorFlow, ce qui cause des erreurs bloquantes.\n","\n","Pour cette raison, j'ai choisi d'utiliser directement le modèle ResNet50 et d'autres modèles de Keras (TensorFlow) avec les poids pré-entraînés sur ImageNet.\n","\n","Cette méthode est plus moderne, plus simple à mettre en œuvre, et compatible avec les dernières versions de TensorFlow.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"d86dbe87acd341fd9860fb9fe44bffcb","colab":{"base_uri":"https://localhost:8080/","height":113},"deepnote_cell_type":"code","execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","execution_millis":2004,"execution_start":1747416940077,"id":"Uwabs5iY-hS_","outputId":"2529d016-e0cd-4333-ade4-1a587fd9ba7b","source_hash":"d8108adf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting imageai==2.0.2\n","  Downloading https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl (151 kB)\n"]}],"source":["!pip3 install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl"]},{"cell_type":"markdown","metadata":{"cell_id":"494a9d2e24624096840aa4cd90c4a006","deepnote_cell_type":"markdown","id":"FueGy5kVb9t1"},"source":["Download the weights generated by the ResNet model, trained on the ImageNet dataset."]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"be2584052a2b44d0ad94e101f99f3542","colab":{"base_uri":"https://localhost:8080/","height":36},"deepnote_cell_type":"code","execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","execution_millis":2505,"execution_start":1747416942137,"id":"cbBX2FrrCHn5","outputId":"402a0ae3-e72e-4cc7-9990-d07c3a711cb9","source_hash":"8b9ba025"},"outputs":[{"data":{"text/plain":["('resnet.h5', <http.client.HTTPMessage at 0x7f929010f9d0>)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import urllib.request\n","import os\n","urllib.request.urlretrieve('https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5', 'resnet.h5')"]},{"cell_type":"markdown","metadata":{"cell_id":"87239ff3985a4e2aaf91b5260b3451cc","deepnote_cell_type":"markdown","id":"skF17MKBcKEa"},"source":["Download the picture which we will ateempt to classify using the model."]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"d6ccedadb3ca4140b30b2bfc221ee734","colab":{"base_uri":"https://localhost:8080/","height":36},"deepnote_cell_type":"code","execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","execution_millis":277,"execution_start":1747416944697,"id":"p37_r6xoI7HQ","outputId":"9537b3a3-eeb4-4117-a00e-7476e22b5938","source_hash":"8c8ae7c5"},"outputs":[{"data":{"text/plain":["('cat.jpg', <http.client.HTTPMessage at 0x7f9290163a30>)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["urllib.request.urlretrieve('https://upload.wikimedia.org/wikipedia/commons/b/bb/Kittyply_edit1.jpg','cat.jpg')"]},{"cell_type":"markdown","metadata":{"cell_id":"e623678da2904bbdb20cfec106104fc0","deepnote_cell_type":"markdown","id":"jfMIEIm5cQfi"},"source":["# Tasks"]},{"cell_type":"markdown","metadata":{"cell_id":"acaf49da64494128b26ba11689319754","deepnote_cell_type":"markdown","id":"DcrTChmEcS7I"},"source":["Refer to the ImageAI [documentation](https://imageai.readthedocs.io/en/latest/) to complete the tasks.\n","\n","*   Create an instance of `ImagePrediction()`.\n","*   Since we will be using weights trained on ResNet, set the model type to ResNet.\n","*   Set model path to the pre-trained weights you downloaded earlier.\n","*   Finally, load the model."]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"295c9a79f80c490c9c81ad71027fe483","deepnote_cell_type":"code","execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","execution_millis":6358,"execution_start":1747416945017,"id":"mtQ5tCwDcXty","source_hash":"b75b5bae"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-05-16 17:35:45.229382: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2025-05-16 17:35:45.232955: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2025-05-16 17:35:45.242183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1747416945.256287     481 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1747416945.260486     481 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1747416945.273060     481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1747416945.273077     481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1747416945.273079     481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1747416945.273081     481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-05-16 17:35:45.277375: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","/root/venv/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","2025-05-16 17:35:48.733346: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"]}],"source":["# your code:\n","from tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","# Charger le modèle ResNet50 pré-entraîné sur ImageNet\n","model = ResNet50(weights='imagenet')\n","\n","# Chemin vers l'image\n","img_path = 'cat.jpg'\n","\n","# Charger et prétraiter l'image\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","# Prédire les classes\n","preds = model.predict(x)"]},{"cell_type":"markdown","metadata":{"cell_id":"643c6d6ef2fe4d3a8e2ccfe1cc442748","deepnote_cell_type":"markdown","id":"dHkniUi9cXlK"},"source":["Return top 3 predictions and their corresponding probabilities for the image."]},{"cell_type":"code","execution_count":5,"metadata":{"allow_embed":false,"cell_id":"5d2bd8bdc40e411d968cb15513b78f2e","deepnote_cell_type":"code","execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","execution_millis":0,"execution_start":1747416951427,"id":"mtQ5tCwDcXty","source_hash":"a000abcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["1. tabby (n02123045): 39.71%\n","2. Egyptian_cat (n02124075): 32.17%\n","3. tiger_cat (n02123159): 23.26%\n"]}],"source":["# your code:\n","for i, (imagenet_id, label, prob) in enumerate(decode_predictions(preds, top=3)[0]):\n","    print(f\"{i+1}. {label} ({imagenet_id}): {prob:.2%}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"a822c797faf043d1aa12915c3a329d5e","deepnote_cell_type":"markdown","id":"dHkniUi9cXlK"},"source":["Modele EfficientNet"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"fc7b358786864c64b724f04d76e87edf","deepnote_cell_type":"code","execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","execution_millis":3776,"execution_start":1747416951487,"source_hash":"f5b0d917"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","1. leopard (n02128385): 19.83%\n","2. spider_web (n04275548): 15.63%\n","3. snow_leopard (n02128757): 2.73%\n"]}],"source":["from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input, decode_predictions\n","model_eff = EfficientNetB0(weights='imagenet')\n","\n","# Prédire les classes\n","preds_eff = model_eff.predict(x)\n","\n","# Return top 3 predictions and their corresponding probabilities for the image.\n","for i, (imagenet_id, label, prob) in enumerate(decode_predictions(preds_eff, top=3)[0]):\n","    print(f\"{i+1}. {label} ({imagenet_id}): {prob:.2%}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"c437e56fe2d4426aab4a5e0718e2792c","deepnote_cell_type":"markdown","id":"dHkniUi9cXlK"},"source":["Modele Inception"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"1ab42c4d99344745b0a4c852a8332c86","deepnote_cell_type":"code","execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","execution_millis":4572,"execution_start":1747416955317,"source_hash":"d42f72e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","1. tabby (n02123045): 77.78%\n","2. tiger_cat (n02123159): 18.39%\n","3. Egyptian_cat (n02124075): 2.08%\n"]}],"source":["from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n","import numpy as np\n","\n","# Load the InceptionV3 model with pre-trained weights\n","model_incep = InceptionV3(weights='imagenet')\n","\n","# Path to the input image\n","img_path = 'cat.jpg'\n","\n","# Load and preprocess the image to the required size for InceptionV3 (299x299)\n","img = image.load_img(img_path, target_size=(299, 299))  # Correct input size\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","# Predict the classes\n","preds_incep = model_incep.predict(x)\n","\n","# Return top 3 predictions and their corresponding probabilities for the image.\n","for i, (imagenet_id, label, prob) in enumerate(decode_predictions(preds_incep, top=3)[0]):\n","    print(f\"{i+1}. {label} ({imagenet_id}): {prob:.2%}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"a20e3dc97b8b4906b0eb89aaafefc8cd","deepnote_cell_type":"markdown","id":"dHkniUi9cXlK"},"source":["Modele DenseNet"]},{"cell_type":"code","execution_count":8,"metadata":{"cell_id":"a9c51bb33ccc4830894b3d360bec2806","deepnote_cell_type":"code","execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","execution_millis":8500,"execution_start":1747416959937,"source_hash":"e926896e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","1. Egyptian_cat (n02124075): 35.03%\n","2. tiger_cat (n02123159): 33.23%\n","3. tabby (n02123045): 29.73%\n"]}],"source":["from tensorflow.keras.applications import DenseNet201\n","\n","# Charger le modèle DenseNet201 pré-entraîné sur ImageNet\n","model = DenseNet201(weights='imagenet')\n","\n","# Chemin vers l'image\n","img_path = 'cat.jpg'\n","\n","# Charger et prétraiter l'image\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","# Prédire les classes\n","preds = model.predict(x)\n","\n","# Return top 3 predictions and their corresponding probabilities for the image.\n","for i, (imagenet_id, label, prob) in enumerate(decode_predictions(preds, top=3)[0]):\n","    print(f\"{i+1}. {label} ({imagenet_id}): {prob:.2%}\")\n"]}],"metadata":{"deepnote_notebook_id":"ff019ee77eec40eaba8785f79601dd92","language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
