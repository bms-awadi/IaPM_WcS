{"cells":[{"cell_type":"markdown","metadata":{"id":"0TbaP_BoYOx5","cell_id":"8fa6db197a804e39aa300c8dd3c89baf","deepnote_cell_type":"markdown"},"source":"# Preparation","block_group":"6ff6293abeba4a0ba6b2bc1d29a2e658"},{"cell_type":"markdown","metadata":{"id":"Ya9uRJFVb1DQ","cell_id":"d007cfc1c4f84b129803214393a1a7a2","deepnote_cell_type":"markdown"},"source":"Install ImageAI.","block_group":"017bcff4ece2417c901afbb96ef2110a"},{"cell_type":"code","metadata":{"id":"Uwabs5iY-hS_","colab":{"height":113,"base_uri":"https://localhost:8080/"},"outputId":"2529d016-e0cd-4333-ade4-1a587fd9ba7b","source_hash":"d8108adf","execution_start":1747416940077,"execution_millis":2004,"execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","cell_id":"d86dbe87acd341fd9860fb9fe44bffcb","deepnote_cell_type":"code"},"source":"!pip3 install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl","block_group":"471764b90f4a4dc19de59c5699f41724","execution_count":1,"outputs":[{"name":"stdout","text":"Collecting imageai==2.0.2\n  Downloading https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl (151 kB)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/8f932840-3485-4f23-8884-031f0a7a5216","content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"FueGy5kVb9t1","cell_id":"494a9d2e24624096840aa4cd90c4a006","deepnote_cell_type":"markdown"},"source":"Download the weights generated by the ResNet model, trained on the ImageNet dataset.","block_group":"712959fce59b498299b1adf52694ac5f"},{"cell_type":"code","metadata":{"id":"cbBX2FrrCHn5","colab":{"height":36,"base_uri":"https://localhost:8080/"},"outputId":"402a0ae3-e72e-4cc7-9990-d07c3a711cb9","source_hash":"8b9ba025","execution_start":1747416942137,"execution_millis":2505,"execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","cell_id":"be2584052a2b44d0ad94e101f99f3542","deepnote_cell_type":"code"},"source":"import urllib.request\nimport os\nurllib.request.urlretrieve('https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5', 'resnet.h5')","block_group":"9b066dc7f01140228447e9104cb113ad","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"('resnet.h5', <http.client.HTTPMessage at 0x7f929010f9d0>)"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/814cd1c4-6ac1-46e9-b6c5-520685c91cc0","content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"skF17MKBcKEa","cell_id":"87239ff3985a4e2aaf91b5260b3451cc","deepnote_cell_type":"markdown"},"source":"Download the picture which we will ateempt to classify using the model.","block_group":"8d725a86629c44a7965857f0b5993e81"},{"cell_type":"code","metadata":{"id":"p37_r6xoI7HQ","colab":{"height":36,"base_uri":"https://localhost:8080/"},"outputId":"9537b3a3-eeb4-4117-a00e-7476e22b5938","source_hash":"8c8ae7c5","execution_start":1747416944697,"execution_millis":277,"execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","cell_id":"d6ccedadb3ca4140b30b2bfc221ee734","deepnote_cell_type":"code"},"source":"urllib.request.urlretrieve('https://upload.wikimedia.org/wikipedia/commons/b/bb/Kittyply_edit1.jpg','cat.jpg')","block_group":"3d098f5a5ebc4627bdae45382598e488","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"('cat.jpg', <http.client.HTTPMessage at 0x7f9290163a30>)"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/349904cb-49f4-4c1b-91a6-0d50b075d9b3","content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"jfMIEIm5cQfi","cell_id":"e623678da2904bbdb20cfec106104fc0","deepnote_cell_type":"markdown"},"source":"# Tasks","block_group":"c0d567a67c6d48aeb472eece29a5387f"},{"cell_type":"markdown","metadata":{"id":"DcrTChmEcS7I","cell_id":"acaf49da64494128b26ba11689319754","deepnote_cell_type":"markdown"},"source":"Refer to the ImageAI [documentation](https://imageai.readthedocs.io/en/latest/) to complete the tasks.\n\n*   Create an instance of `ImagePrediction()`.\n*   Since we will be using weights trained on ResNet, set the model type to ResNet.\n*   Set model path to the pre-trained weights you downloaded earlier.\n*   Finally, load the model.","block_group":"63d8c65ddc3d42c78c565cb061e70866"},{"cell_type":"code","metadata":{"id":"mtQ5tCwDcXty","source_hash":"b75b5bae","execution_start":1747416945017,"execution_millis":6358,"execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","cell_id":"295c9a79f80c490c9c81ad71027fe483","deepnote_cell_type":"code"},"source":"# your code:\nfrom tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\n\n# Charger le modèle ResNet50 pré-entraîné sur ImageNet\nmodel = ResNet50(weights='imagenet')\n\n# Chemin vers l'image\nimg_path = 'cat.jpg'\n\n# Charger et prétraiter l'image\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\n# Prédire les classes\npreds = model.predict(x)","block_group":"86e912ab41fe45e4a2ddb3b61e12d559","execution_count":4,"outputs":[{"name":"stderr","text":"2025-05-16 17:35:45.229382: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-05-16 17:35:45.232955: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-05-16 17:35:45.242183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747416945.256287     481 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747416945.260486     481 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1747416945.273060     481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1747416945.273077     481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1747416945.273079     481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1747416945.273081     481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n2025-05-16 17:35:45.277375: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n/root/venv/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n2025-05-16 17:35:48.733346: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/773fc138-039e-4d6d-9a61-2861f69f148b","content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"dHkniUi9cXlK","cell_id":"643c6d6ef2fe4d3a8e2ccfe1cc442748","deepnote_cell_type":"markdown"},"source":"Return top 3 predictions and their corresponding probabilities for the image.","block_group":"abf9d728cfc245d39d43bce9308ec69f"},{"cell_type":"code","metadata":{"id":"mtQ5tCwDcXty","allow_embed":false,"source_hash":"a000abcb","execution_start":1747416951427,"execution_millis":0,"execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","cell_id":"5d2bd8bdc40e411d968cb15513b78f2e","deepnote_cell_type":"code"},"source":"# your code:\nfor i, (imagenet_id, label, prob) in enumerate(decode_predictions(preds, top=3)[0]):\n    print(f\"{i+1}. {label} ({imagenet_id}): {prob:.2%}\")","block_group":"94f9460b22b84bc29532e0c94d498f36","execution_count":5,"outputs":[{"name":"stdout","text":"1. tabby (n02123045): 39.71%\n2. Egyptian_cat (n02124075): 32.17%\n3. tiger_cat (n02123159): 23.26%\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/49a8d65b-c29a-49b8-a8e5-9158647594d7","content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"dHkniUi9cXlK","cell_id":"a822c797faf043d1aa12915c3a329d5e","deepnote_cell_type":"markdown"},"source":"Modele EfficientNet","block_group":"c54998faa77f406da3e50bb66bfdf375"},{"cell_type":"code","metadata":{"source_hash":"f5b0d917","execution_start":1747416951487,"execution_millis":3776,"execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","cell_id":"fc7b358786864c64b724f04d76e87edf","deepnote_cell_type":"code"},"source":"from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input, decode_predictions\nmodel_eff = EfficientNetB0(weights='imagenet')\n\n# Prédire les classes\npreds_eff = model_eff.predict(x)\n\n# Return top 3 predictions and their corresponding probabilities for the image.\nfor i, (imagenet_id, label, prob) in enumerate(decode_predictions(preds_eff, top=3)[0]):\n    print(f\"{i+1}. {label} ({imagenet_id}): {prob:.2%}\")","block_group":"6e2f2167d0c84ae1a317980547a05507","execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n1. leopard (n02128385): 19.83%\n2. spider_web (n04275548): 15.63%\n3. snow_leopard (n02128757): 2.73%\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/8e80576a-48f1-4aa0-b5ce-f0b55b927844","content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"dHkniUi9cXlK","cell_id":"c437e56fe2d4426aab4a5e0718e2792c","deepnote_cell_type":"markdown"},"source":"Modele Inception","block_group":"eeb2fa5dafb4407ea9b2ffacd5b83b41"},{"cell_type":"code","metadata":{"source_hash":"d42f72e8","execution_start":1747416955317,"execution_millis":4572,"execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","cell_id":"1ab42c4d99344745b0a4c852a8332c86","deepnote_cell_type":"code"},"source":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\nimport numpy as np\n\n# Load the InceptionV3 model with pre-trained weights\nmodel_incep = InceptionV3(weights='imagenet')\n\n# Path to the input image\nimg_path = 'cat.jpg'\n\n# Load and preprocess the image to the required size for InceptionV3 (299x299)\nimg = image.load_img(img_path, target_size=(299, 299))  # Correct input size\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\n# Predict the classes\npreds_incep = model_incep.predict(x)\n\n# Return top 3 predictions and their corresponding probabilities for the image.\nfor i, (imagenet_id, label, prob) in enumerate(decode_predictions(preds_incep, top=3)[0]):\n    print(f\"{i+1}. {label} ({imagenet_id}): {prob:.2%}\")","block_group":"98136a480d6d4fcb891fa5468410e7ac","execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n1. tabby (n02123045): 77.78%\n2. tiger_cat (n02123159): 18.39%\n3. Egyptian_cat (n02124075): 2.08%\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/c022a60d-31c4-449c-b779-563097111bb2","content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"dHkniUi9cXlK","cell_id":"a20e3dc97b8b4906b0eb89aaafefc8cd","deepnote_cell_type":"markdown"},"source":"Modele DenseNet","block_group":"7a9ef238eeca4129aaff96d0fc28240f"},{"cell_type":"code","metadata":{"source_hash":"e926896e","execution_start":1747416959937,"execution_millis":8500,"execution_context_id":"788b96af-3437-4b94-8792-0c706229a378","cell_id":"a9c51bb33ccc4830894b3d360bec2806","deepnote_cell_type":"code"},"source":"from tensorflow.keras.applications import DenseNet201\n\n# Charger le modèle DenseNet201 pré-entraîné sur ImageNet\nmodel = DenseNet201(weights='imagenet')\n\n# Chemin vers l'image\nimg_path = 'cat.jpg'\n\n# Charger et prétraiter l'image\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\n# Prédire les classes\npreds = model.predict(x)\n\n# Return top 3 predictions and their corresponding probabilities for the image.\nfor i, (imagenet_id, label, prob) in enumerate(decode_predictions(preds, top=3)[0]):\n    print(f\"{i+1}. {label} ({imagenet_id}): {prob:.2%}\")\n","block_group":"ef42a182eec54aec9eb991cdfe215f62","execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n1. Egyptian_cat (n02124075): 35.03%\n2. tiger_cat (n02123159): 33.23%\n3. tabby (n02123045): 29.73%\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/a12827d9-e959-4ac6-9db2-63838bc1a5a9","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b66e90c1-d5c9-4c04-97ae-011e24978773' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"ff019ee77eec40eaba8785f79601dd92"}}